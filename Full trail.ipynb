{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bd859ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('Books.csv')\n",
    "users = pd.read_csv('Users.csv')\n",
    "ratings = pd.read_csv('Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9f287be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc19d11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "841360f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271360, 8)\n",
      "(1149780, 3)\n",
      "(278858, 3)\n"
     ]
    }
   ],
   "source": [
    "print(books.shape)\n",
    "print(ratings.shape)\n",
    "print(users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "588cb43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                   0\n",
       "Book-Title             0\n",
       "Book-Author            1\n",
       "Year-Of-Publication    0\n",
       "Publisher              2\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a965dcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID          0\n",
       "Location         0\n",
       "Age         110762\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ada5cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID        0\n",
       "ISBN           0\n",
       "Book-Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79585a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3737eb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "565b0555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08271d2c",
   "metadata": {},
   "source": [
    "## Popularity Based Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dccf449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Storm: The Civil War Diary of ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Always Have Popsicles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple Magic (The Collector's series)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ask Lily (Young Women of Faith: Lily Series, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyond IBM: Leadership Marketing and Finance ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241066</th>\n",
       "      <td>Ã?Â?lpiraten.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241067</th>\n",
       "      <td>Ã?Â?rger mit Produkt X. Roman.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241068</th>\n",
       "      <td>Ã?Â?sterlich leben.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241069</th>\n",
       "      <td>Ã?Â?stlich der Berge.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241070</th>\n",
       "      <td>Ã?Â?thique en toc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241071 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Book-Title  num_ratings\n",
       "0        A Light in the Storm: The Civil War Diary of ...            4\n",
       "1                                   Always Have Popsicles            1\n",
       "2                    Apple Magic (The Collector's series)            1\n",
       "3        Ask Lily (Young Women of Faith: Lily Series, ...            1\n",
       "4        Beyond IBM: Leadership Marketing and Finance ...            1\n",
       "...                                                   ...          ...\n",
       "241066                                      Ã?Â?lpiraten.            2\n",
       "241067                     Ã?Â?rger mit Produkt X. Roman.            4\n",
       "241068                                Ã?Â?sterlich leben.            1\n",
       "241069                              Ã?Â?stlich der Berge.            3\n",
       "241070                                  Ã?Â?thique en toc            2\n",
       "\n",
       "[241071 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_with_name = ratings.merge(books,on='ISBN')\n",
    "\n",
    "num_rating_df = ratings_with_name.groupby('Book-Title').count()['Book-Rating'].reset_index()\n",
    "num_rating_df.rename(columns={'Book-Rating':'num_ratings'},inplace=True)\n",
    "num_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "394a6689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Storm: The Civil War Diary of ...</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Always Have Popsicles</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple Magic (The Collector's series)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ask Lily (Young Women of Faith: Lily Series, ...</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyond IBM: Leadership Marketing and Finance ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241066</th>\n",
       "      <td>Ã?Â?lpiraten.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241067</th>\n",
       "      <td>Ã?Â?rger mit Produkt X. Roman.</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241068</th>\n",
       "      <td>Ã?Â?sterlich leben.</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241069</th>\n",
       "      <td>Ã?Â?stlich der Berge.</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241070</th>\n",
       "      <td>Ã?Â?thique en toc</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241071 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Book-Title  avg_rating\n",
       "0        A Light in the Storm: The Civil War Diary of ...    2.250000\n",
       "1                                   Always Have Popsicles    0.000000\n",
       "2                    Apple Magic (The Collector's series)    0.000000\n",
       "3        Ask Lily (Young Women of Faith: Lily Series, ...    8.000000\n",
       "4        Beyond IBM: Leadership Marketing and Finance ...    0.000000\n",
       "...                                                   ...         ...\n",
       "241066                                      Ã?Â?lpiraten.    0.000000\n",
       "241067                     Ã?Â?rger mit Produkt X. Roman.    5.250000\n",
       "241068                                Ã?Â?sterlich leben.    7.000000\n",
       "241069                              Ã?Â?stlich der Berge.    2.666667\n",
       "241070                                  Ã?Â?thique en toc    4.000000\n",
       "\n",
       "[241071 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rating_df = ratings_with_name.groupby('Book-Title').mean()['Book-Rating'].reset_index()\n",
    "avg_rating_df.rename(columns={'Book-Rating':'avg_rating'},inplace=True)\n",
    "avg_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "881a0791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Storm: The Civil War Diary of ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Always Have Popsicles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple Magic (The Collector's series)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ask Lily (Young Women of Faith: Lily Series, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyond IBM: Leadership Marketing and Finance ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241066</th>\n",
       "      <td>Ã?Â?lpiraten.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241067</th>\n",
       "      <td>Ã?Â?rger mit Produkt X. Roman.</td>\n",
       "      <td>4</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241068</th>\n",
       "      <td>Ã?Â?sterlich leben.</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241069</th>\n",
       "      <td>Ã?Â?stlich der Berge.</td>\n",
       "      <td>3</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241070</th>\n",
       "      <td>Ã?Â?thique en toc</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241071 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Book-Title  num_ratings  \\\n",
       "0        A Light in the Storm: The Civil War Diary of ...            4   \n",
       "1                                   Always Have Popsicles            1   \n",
       "2                    Apple Magic (The Collector's series)            1   \n",
       "3        Ask Lily (Young Women of Faith: Lily Series, ...            1   \n",
       "4        Beyond IBM: Leadership Marketing and Finance ...            1   \n",
       "...                                                   ...          ...   \n",
       "241066                                      Ã?Â?lpiraten.            2   \n",
       "241067                     Ã?Â?rger mit Produkt X. Roman.            4   \n",
       "241068                                Ã?Â?sterlich leben.            1   \n",
       "241069                              Ã?Â?stlich der Berge.            3   \n",
       "241070                                  Ã?Â?thique en toc            2   \n",
       "\n",
       "        avg_rating  \n",
       "0         2.250000  \n",
       "1         0.000000  \n",
       "2         0.000000  \n",
       "3         8.000000  \n",
       "4         0.000000  \n",
       "...            ...  \n",
       "241066    0.000000  \n",
       "241067    5.250000  \n",
       "241068    7.000000  \n",
       "241069    2.666667  \n",
       "241070    4.000000  \n",
       "\n",
       "[241071 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_df = num_rating_df.merge(avg_rating_df,on='Book-Title')\n",
    "popular_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94bcb102",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df = popular_df[popular_df['num_ratings']>=250].sort_values('avg_rating',ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06cd4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_df = popular_df.merge(books,on='Book-Title').drop_duplicates('Book-Title')[['Book-Title','Book-Author','Image-URL-M','num_ratings','avg_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34c2b167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.amazon.com/images/P/0439136350.01.MZZZZZZZ.jpg'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_df['Image-URL-M'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649e169",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Based Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3facbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ratings_with_name.groupby('User-ID').count()['Book-Rating'] > 200\n",
    "padhe_likhe_users = x[x].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "656b3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rating = ratings_with_name[ratings_with_name['User-ID'].isin(padhe_likhe_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8574b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = filtered_rating.groupby('Book-Title').count()['Book-Rating']>=50\n",
    "famous_books = y[y].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83d39b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3707ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = final_ratings.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10d40805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb043daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>User-ID</th>\n",
       "      <th>254</th>\n",
       "      <th>2276</th>\n",
       "      <th>2766</th>\n",
       "      <th>2977</th>\n",
       "      <th>3363</th>\n",
       "      <th>4017</th>\n",
       "      <th>4385</th>\n",
       "      <th>6251</th>\n",
       "      <th>6323</th>\n",
       "      <th>6543</th>\n",
       "      <th>...</th>\n",
       "      <th>271705</th>\n",
       "      <th>273979</th>\n",
       "      <th>274004</th>\n",
       "      <th>274061</th>\n",
       "      <th>274301</th>\n",
       "      <th>274308</th>\n",
       "      <th>275970</th>\n",
       "      <th>277427</th>\n",
       "      <th>277639</th>\n",
       "      <th>278418</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book-Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st to Die: A Novel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd Chance</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Blondes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Bend in the Road</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year of Wonders</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You Belong To Me</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zen and the Art of Motorcycle Maintenance: An Inquiry into Values</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoya</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\O\\\" Is for Outlaw\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows × 810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "User-ID                                             254     2276    2766    \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   9.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0    10.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     7.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             2977    3363    4017    \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        7.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             4385    6251    6323    \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             6543    ...  271705  \\\n",
       "Book-Title                                                  ...           \n",
       "1984                                                   0.0  ...    10.0   \n",
       "1st to Die: A Novel                                    9.0  ...     0.0   \n",
       "2nd Chance                                             0.0  ...     0.0   \n",
       "4 Blondes                                              0.0  ...     0.0   \n",
       "A Bend in the Road                                     0.0  ...     0.0   \n",
       "...                                                    ...  ...     ...   \n",
       "Year of Wonders                                        0.0  ...     0.0   \n",
       "You Belong To Me                                       0.0  ...     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0  ...     0.0   \n",
       "Zoya                                                   0.0  ...     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0  ...     0.0   \n",
       "\n",
       "User-ID                                             273979  274004  274061  \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        9.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             274301  274308  275970  \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    8.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             277427  277639  278418  \n",
       "Book-Title                                                                  \n",
       "1984                                                   0.0     0.0     0.0  \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0  \n",
       "2nd Chance                                             0.0     0.0     0.0  \n",
       "4 Blondes                                              0.0     0.0     0.0  \n",
       "A Bend in the Road                                     0.0     0.0     0.0  \n",
       "...                                                    ...     ...     ...  \n",
       "Year of Wonders                                        0.0     0.0     0.0  \n",
       "You Belong To Me                                       0.0     0.0     0.0  \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0  \n",
       "Zoya                                                   0.0     0.0     0.0  \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0  \n",
       "\n",
       "[706 rows x 810 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f608d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "edcdea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = cosine_similarity(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "785cf2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706, 706)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e48d1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(book_name):\n",
    "    # index fetch\n",
    "    index = np.where(pt.index==book_name)[0][0]\n",
    "    similar_items = sorted(list(enumerate(similarity_scores[index])),key=lambda x:x[1],reverse=True)[1:5]\n",
    "    \n",
    "    data = []\n",
    "    for i in similar_items:\n",
    "        item = []\n",
    "        temp_df = books[books['Book-Title'] == pt.index[i[0]]]\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))\n",
    "        \n",
    "        data.append(item)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a87a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Animal Farm',\n",
       "  'George Orwell',\n",
       "  'http://images.amazon.com/images/P/0451526341.01.MZZZZZZZ.jpg'],\n",
       " [\"The Handmaid's Tale\",\n",
       "  'Margaret Atwood',\n",
       "  'http://images.amazon.com/images/P/0449212602.01.MZZZZZZZ.jpg'],\n",
       " ['Brave New World',\n",
       "  'Aldous Huxley',\n",
       "  'http://images.amazon.com/images/P/0060809833.01.MZZZZZZZ.jpg'],\n",
       " ['The Vampire Lestat (Vampire Chronicles, Book II)',\n",
       "  'ANNE RICE',\n",
       "  'http://images.amazon.com/images/P/0345313860.01.MZZZZZZZ.jpg']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('1984')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50f2ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Handmaid's Tale\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.index[545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a665e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(popular_df,open('popular.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a4dd9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271354</th>\n",
       "      <td>0449906736</td>\n",
       "      <td>Flashpoints: Promise and Peril in a New World</td>\n",
       "      <td>Robin Wright</td>\n",
       "      <td>1993</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449906736.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449906736.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449906736.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271359</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "271354  0449906736      Flashpoints: Promise and Peril in a New World   \n",
       "271356  0525447644                            From One to One Hundred   \n",
       "271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271358  0192126040                        Republic (World's Classics)   \n",
       "271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                 Book-Author Year-Of-Publication  \\\n",
       "0         Mark P. O. Morford                2002   \n",
       "1       Richard Bruce Wright                2001   \n",
       "2               Carlo D'Este                1991   \n",
       "3           Gina Bari Kolata                1999   \n",
       "4            E. J. W. Barber                1999   \n",
       "...                      ...                 ...   \n",
       "271354          Robin Wright                1993   \n",
       "271356            Teri Sloat                1991   \n",
       "271357      Christine Wicker                2004   \n",
       "271358                 Plato                1996   \n",
       "271359   Christopher  Biffle                2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp; Company   \n",
       "...                                                  ...   \n",
       "271354                                  Ballantine Books   \n",
       "271356                                      Dutton Books   \n",
       "271357                                HarperSanFrancisco   \n",
       "271358                           Oxford University Press   \n",
       "271359  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271354  http://images.amazon.com/images/P/0449906736.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271354  http://images.amazon.com/images/P/0449906736.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271354  http://images.amazon.com/images/P/0449906736.0...  \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[242135 rows x 8 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.drop_duplicates('Book-Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c4587be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pt,open('pt.pkl','wb'))\n",
    "pickle.dump(books,open('books.pkl','wb'))\n",
    "pickle.dump(similarity_scores,open('similarity_scores.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441310e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c00f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec449b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ceb811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f42ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classical Mythology', 'Mythology', 'Mythology', 'Mythology', 'Mythology', 'Mythology', 'Mythology', 'Mythology', 'Mythology', 'Mythology']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "# Preprocessing\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = books_with_ratings.dropna(subset=['Book-Title'])\n",
    "\n",
    "# Content-Based Recommender: Simplified\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "indices = pd.Series(books_with_ratings.index, index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    idx = indices[book_title]\n",
    "    \n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(count_matrix[idx], count_matrix)\n",
    "    \n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:50]  # Increase to get a larger pool of similar books\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Predict ratings for these books for the given user\n",
    "    books_predictions = [(books_with_ratings['Book-Title'].iloc[i], svd.predict(user_id, books_with_ratings['ISBN'].iloc[i]).est) for i in book_indices]\n",
    "    books_predictions.sort(key=lambda x: x[1], reverse=True)  # Sort by predicted rating\n",
    "\n",
    "    # Select top 10\n",
    "    top_books = [book[0] for book in books_predictions[:10]]\n",
    "    \n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Classical Mythology\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fd2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.5044  3.5024  3.4987  3.5113  3.5028  3.5039  0.0042  \n",
      "Fit time          19.52   20.28   21.09   20.34   20.62   20.37   0.51    \n",
      "Test time         3.44    2.63    2.48    2.48    2.63    2.73    0.36    \n",
      "{'test_rmse': array([3.50435508, 3.50241154, 3.49868794, 3.51134093, 3.50277328]), 'fit_time': (19.516736030578613, 20.278340816497803, 21.091652631759644, 20.337438583374023, 20.61928391456604), 'test_time': (3.439271926879883, 2.63273024559021, 2.4783668518066406, 2.482888698577881, 2.627638816833496)}\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "def evaluate_model(model, data):\n",
    "    cross_val_results = cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "    return cross_val_results\n",
    "\n",
    "evaluation_results = evaluate_model(svd, data)\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed16b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mythology (Cliffs Notes)', 'Age of Fable or Beauties of Mythology (Bulfinch Mythology)', \"Bulfinch's Mythology\", 'Classical mythology', 'Brush Up Your Mythology!', 'Whos Who In Mythology', \"Crowell's Handbook of Classical Mythology (A Crowell reference book)\", 'Greek Mythology', 'Illustrated Dictionary of Mythology', 'The Dictionary of Classical Mythology']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "# Preprocessing\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = books_with_ratings.dropna(subset=['Book-Title'])\n",
    "\n",
    "# Content-Based Recommender: Simplified\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "indices = pd.Series(books_with_ratings.index, index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(count_matrix[idx], count_matrix)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]  # Increased to get a larger pool of similar books\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings['Book-Title'].iloc[i]\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings['ISBN'].iloc[i]).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Classical Mythology\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48eceb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mythology', \"Bulfinch's Mythology (Laurel Classic)\", 'The Song of Eve: Mythology and Symbols of the Goddess', 'The Well-Educated Mind: A Guide to the Classical Education You Never Had', 'The Classical Greek Reader', 'Dictionary of Mythology: Mainly Classical', 'The Illustrated Guide to Celtic Mythology', 'The Oxford History of the Classical World', 'Classical Music for Dummies', 'The Oxford Companion to Classical Civilization']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "# Filter out zero ratings\n",
    "filtered_ratings = ratings[ratings['Book-Rating'] > 0]\n",
    "\n",
    "# Merge books with filtered ratings\n",
    "books_with_ratings = pd.merge(books, filtered_ratings, on='ISBN')\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "books_with_ratings = books_with_ratings.dropna(subset=['Book-Title'])\n",
    "\n",
    "# Content-Based Recommender: Simplified\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "indices = pd.Series(books_with_ratings.index, index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(count_matrix[idx], count_matrix)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]  # Increased pool of similar books\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings['Book-Title'].iloc[i]\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings['ISBN'].iloc[i]).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "print(recommended_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76459787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mythology', \"Bulfinch's Mythology (Laurel Classic)\", 'The Well-Educated Mind: A Guide to the Classical Education You Never Had', 'Dictionary of Mythology: Mainly Classical', 'Mythology (Collins Gem)', 'Mythology: Timeless Tales of Gods and Heroes', 'Classical mythology', \"Bulfinch's Mythology\", 'Hawaiian Mythology', \"Who's Who in Non-Classical Mythology\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "# Filter out zero ratings\n",
    "filtered_ratings = ratings[ratings['Book-Rating'] > 0]\n",
    "\n",
    "# Merge books with filtered ratings\n",
    "books_with_ratings = pd.merge(books, filtered_ratings, on='ISBN')\n",
    "\n",
    "# Define minimum number of ratings required for books and users\n",
    "min_book_ratings = 1\n",
    "min_user_ratings = 1\n",
    "\n",
    "# Filter books and users based on defined thresholds\n",
    "book_counts = books_with_ratings['ISBN'].value_counts()\n",
    "user_counts = books_with_ratings['User-ID'].value_counts()\n",
    "books_with_ratings = books_with_ratings[books_with_ratings['ISBN'].isin(book_counts[book_counts >= min_book_ratings].index)]\n",
    "books_with_ratings = books_with_ratings[books_with_ratings['User-ID'].isin(user_counts[user_counts >= min_user_ratings].index)]\n",
    "\n",
    "# Preprocessing to drop NaNs in 'Book-Title'\n",
    "books_with_ratings = books_with_ratings.dropna(subset=['Book-Title'])\n",
    "\n",
    "# Content-Based Recommender: Simplified\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "indices = pd.Series(books_with_ratings.index, index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(count_matrix[idx], count_matrix)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]  # Increased pool of similar books\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings['Book-Title'].iloc[i]\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings['ISBN'].iloc[i]).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "print(recommended_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39033f0",
   "metadata": {},
   "source": [
    "The code provided is an example of a Hybrid Recommendation System. It combines elements of both Content-Based Filtering and Collaborative Filtering to generate recommendations. Let's break down how each part contributes to the hybrid model:\n",
    "\n",
    "Content-Based Filtering: This part is achieved through the use of CountVectorizer to transform the book titles into a count matrix and then applying cosine similarity to find books with similar titles. This method focuses on the content (in this case, the titles of the books) to find items similar to the user's past preferences or specific input (the given book title).\n",
    "\n",
    "Collaborative Filtering: This aspect is implemented using the surprise library, where the SVD (Singular Value Decomposition) algorithm is used to predict how a user might rate books based on how similar users have rated them. This method leverages the collective ratings of users to make recommendations.\n",
    "\n",
    "Hybrid Approach: The system first finds books similar to the input book title (content-based) and then filters and ranks these books based on the predicted preferences of the user (collaborative filtering). The final recommendation list is sorted based on these predicted ratings.\n",
    "\n",
    "By combining these two approaches, the hybrid model aims to leverage both the content features of the items (books in this case) and the user-item interaction data, providing a more nuanced set of recommendations than either method would on its own. This approach can help alleviate some common issues in recommendation systems, such as the cold start problem and the limitation of recommending items only based on user interaction history or item features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef65242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.6308  1.6417  1.6374  1.6335  1.6371  1.6361  0.0037  \n",
      "Fit time          7.07    7.24    7.73    7.52    7.31    7.38    0.23    \n",
      "Test time         0.91    0.91    0.60    0.94    0.89    0.85    0.13    \n",
      "{'test_rmse': array([1.63082637, 1.64173699, 1.6374449 , 1.63350614, 1.63711106]), 'fit_time': (7.068379878997803, 7.240798711776733, 7.732605934143066, 7.5235371589660645, 7.314286231994629), 'test_time': (0.9125139713287354, 0.9053792953491211, 0.6012551784515381, 0.9425902366638184, 0.8931059837341309)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "\n",
    "# Filter out zero ratings\n",
    "filtered_ratings = ratings[ratings['Book-Rating'] > 0]\n",
    "\n",
    "# Merge books with filtered ratings\n",
    "books_with_ratings = pd.merge(books, filtered_ratings, on='ISBN')\n",
    "\n",
    "# Define minimum number of ratings required for books and users\n",
    "min_book_ratings = 1\n",
    "min_user_ratings = 1\n",
    "\n",
    "# Filter books and users based on defined thresholds\n",
    "book_counts = books_with_ratings['ISBN'].value_counts()\n",
    "user_counts = books_with_ratings['User-ID'].value_counts()\n",
    "books_with_ratings = books_with_ratings[books_with_ratings['ISBN'].isin(book_counts[book_counts >= min_book_ratings].index)]\n",
    "books_with_ratings = books_with_ratings[books_with_ratings['User-ID'].isin(user_counts[user_counts >= min_user_ratings].index)]\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# Output the results\n",
    "print(cross_val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d51869",
   "metadata": {},
   "source": [
    "\n",
    "The evaluation results you provided indicate an RMSE (Root Mean Square Error) with a mean of approximately 1.6361 across the 5 folds of cross-validation. Here's how to interpret these results:\n",
    "\n",
    "RMSE (Root Mean Square Error): RMSE is a standard metric for evaluating the accuracy of a prediction model. It measures the average magnitude of the prediction errors, i.e., the differences between the predicted values and the actual values. An RMSE of 0 would mean perfect predictions, which is typically not achievable in real-world scenarios.\n",
    "\n",
    "Mean RMSE of 1.6361: This value suggests that, on average, the predicted ratings by your model differ from the actual ratings by about 1.6361 points on the rating scale (assuming your ratings are on a scale from 1 to 10).\n",
    "\n",
    "Standard Deviation of RMSE (0.0037): The low standard deviation indicates that the model's performance is relatively consistent across different subsets of your data.\n",
    "\n",
    "Is the Model Good?\n",
    "Context of RMSE Value: The acceptability of the RMSE value depends on the context and the specific application. In a 10-point rating system, an average error of around 1.6 might be considered reasonable, but this can vary depending on the complexity of the data and the domain. For instance, in some scenarios, even a small error can be significant, while in others, a larger error is acceptable.\n",
    "\n",
    "Comparative Analysis: To better understand if this is a good RMSE value, you could compare it with baseline models or other algorithms. If your model performs significantly better than a basic model (like one that always predicts the average rating), it indicates a good model.\n",
    "\n",
    "User Satisfaction: Ultimately, the success of a recommendation system is also measured by user satisfaction, which can be gauged through user feedback, engagement metrics, and practical usability tests.\n",
    "\n",
    "Room for Improvement: If you aim to improve the model further, consider experimenting with different algorithms, tuning hyperparameters, or enriching the dataset with more features.\n",
    "\n",
    "In summary, while the RMSE value provides a quantitative measure of your model's accuracy, assessing its quality also requires qualitative considerations and possibly comparisons with other models or baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d6025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bf35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa3f7efd",
   "metadata": {},
   "source": [
    "# NEW TRAILS BY ADDING MORE INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07e1fbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Into the Wild', 'Slaughterhouse-Five', 'The Client', 'Among Schoolchildren', 'Three Fates', 'Slackjaw', 'The Summons', 'The Moviegoer', 'The Bottoms', 'Shopgirl']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('location', OneHotEncoder(handle_unknown='ignore'), ['Location']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Classical Mythology\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3377d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Two codes for evaluation, one for collabrative filtering another for content based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22b48e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.5022  3.5004  3.4960  3.5081  3.4942  3.5002  0.0049  \n",
      "Fit time          19.32   24.44   21.62   22.84   19.97   21.64   1.87    \n",
      "Test time         4.79    3.61    3.38    3.19    2.78    3.55    0.68    \n",
      "{'test_rmse': array([3.50217204, 3.50037164, 3.49603394, 3.50809783, 3.49422042]), 'fit_time': (19.31854009628296, 24.43724274635315, 21.617775678634644, 22.8384530544281, 19.973925590515137), 'test_time': (4.788440704345703, 3.611894130706787, 3.383833646774292, 3.190612316131592, 2.77546763420105)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa077fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8253e3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006012063945992824"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2ba28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23465dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded6a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fef3b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_rating(rating):\n",
    "    if rating <= 4:\n",
    "        return 'Low'\n",
    "    elif rating <= 7:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "441553bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Slaughterhouse-Five', 'The Partner', 'The Associate', 'Three Fates', \"Who's Who in Non-Classical Mythology\", 'Unexpected', 'Shopgirl', 'Dreamcatcher', 'The Client', 'The Summons']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Split and clean the 'Location' column in users_df\n",
    "users[['City', 'State', 'Country']] = users['Location'].str.split(',', n=2, expand=True)\n",
    "users['City'] = users['City'].str.strip()\n",
    "users['State'] = users['State'].str.strip()\n",
    "users['Country'] = users['Country'].str.strip()\n",
    "\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Rating-Category'] = books_with_ratings['Book-Rating'].apply(categorize_rating)\n",
    "rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "books_with_ratings['Numeric-Rating-Category'] = books_with_ratings['Rating-Category'].map(rating_to_numeric)\n",
    "\n",
    "median_age = books_with_ratings['Age'].median()\n",
    "books_with_ratings['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('location', OneHotEncoder(handle_unknown='ignore'), ['Location']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'ISBN', 'Numeric-Rating-Category']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Classical Mythology\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bccd4c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7355  0.7385  0.7385  0.7372  0.7370  0.7373  0.0011  \n",
      "Fit time          14.26   14.49   14.67   15.43   15.04   14.78   0.41    \n",
      "Test time         1.45    2.63    1.42    3.22    2.79    2.30    0.73    \n",
      "{'test_rmse': array([0.735502  , 0.73845988, 0.7384513 , 0.73718041, 0.73695016]), 'fit_time': (14.264035701751709, 14.488046646118164, 14.670043230056763, 15.433007717132568, 15.041014194488525), 'test_time': (1.4480071067810059, 2.6349918842315674, 1.4150056838989258, 3.216000556945801, 2.7899835109710693)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005560293901847928"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n",
    "average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85d612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58398b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03b2ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classical Mythology', 'Mythology', 'The Penguin Dictionary of Classical Mythology (Reference Books)', \"Bulfinch's Mythology\", 'Classical Music', 'Classical mythology', 'Comparative Mythology', 'Hawaiian Mythology', 'Greek mythology', \"Mythology and You : Classical Mythology and its Relevance in Today's World\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Split and clean the 'Location' column in users_df\n",
    "users[['City', 'State', 'Country']] = users['Location'].str.split(',', n=2, expand=True)\n",
    "users['City'] = users['City'].str.strip()\n",
    "users['State'] = users['State'].str.strip()\n",
    "users['Country'] = users['Country'].str.strip()\n",
    "\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Rating-Category'] = books_with_ratings['Book-Rating'].apply(categorize_rating)\n",
    "rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "books_with_ratings['Numeric-Rating-Category'] = books_with_ratings['Rating-Category'].map(rating_to_numeric)\n",
    "\n",
    "median_age = books_with_ratings['Age'].median()\n",
    "books_with_ratings['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('location', OneHotEncoder(handle_unknown='ignore'), ['State']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'Book-Title', 'Numeric-Rating-Category']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Classical Mythology\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "623ccf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7359  0.7380  0.7370  0.7372  0.7359  0.7368  0.0008  \n",
      "Fit time          22.79   25.89   25.40   24.83   25.90   24.96   1.15    \n",
      "Test time         4.22    4.42    3.16    3.47    3.96    3.85    0.47    \n",
      "{'test_rmse': array([0.73593546, 0.73799244, 0.73696184, 0.73721835, 0.73594706]), 'fit_time': (22.79499578475952, 25.89400291442871, 25.396962642669678, 24.82599973678589, 25.900165796279907), 'test_time': (4.22303581237793, 4.419001579284668, 3.1600005626678467, 3.473998785018921, 3.964035987854004)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "041eb2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45576695729308214"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b2102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe632ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8a472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22548949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rebecca', 'The Key to Rebecca', 'Rebecca (Compact Books)', \"Rebecca (The world's best reading)\", 'My Cousin Rachel (Common Reader Editions)', 'Q', 'Cry No More', 'Under Fire', 'Now You See It . . .', 'Once']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Split and clean the 'Location' column in users_df\n",
    "users[['City', 'State', 'Country']] = users['Location'].str.split(',', n=2, expand=True)\n",
    "users['City'] = users['City'].str.strip()\n",
    "users['State'] = users['State'].str.strip()\n",
    "users['Country'] = users['Country'].str.strip()\n",
    "\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Rating-Category'] = books_with_ratings['Book-Rating'].apply(categorize_rating)\n",
    "rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "books_with_ratings['Numeric-Rating-Category'] = books_with_ratings['Rating-Category'].map(rating_to_numeric)\n",
    "\n",
    "median_age = books_with_ratings['Age'].median()\n",
    "books_with_ratings['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('location', OneHotEncoder(handle_unknown='ignore'), ['Location']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'Book-Title', 'Numeric-Rating-Category']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Rebecca\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "245ca68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7370  0.7379  0.7353  0.7368  0.7386  0.7371  0.0011  \n",
      "Fit time          34.65   38.75   37.21   37.33   36.71   36.93   1.32    \n",
      "Test time         6.52    5.54    6.16    4.65    6.53    5.88    0.71    \n",
      "{'test_rmse': array([0.73698688, 0.73787366, 0.73530408, 0.73684907, 0.73857673]), 'fit_time': (34.65027379989624, 38.745248317718506, 37.21324896812439, 37.32742714881897, 36.711984395980835), 'test_time': (6.519286632537842, 5.540955066680908, 6.160151958465576, 4.6478376388549805, 6.528259038925171)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41550206306433424"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n",
    "average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "217d171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7392259219930469\n",
      "{'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "## HYer Arameter Tuning \n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_epochs': [5, 10, 20],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.4, 0.6]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# Use the best parameters for SVD\n",
    "algo = SVD(n_epochs=gs.best_params['rmse']['n_epochs'], lr_all=gs.best_params['rmse']['lr_all'], reg_all=gs.best_params['rmse']['reg_all'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ac2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08ce3733",
   "metadata": {},
   "source": [
    "The results from your hyperparameter tuning indicate that the best parameters for the SVD algorithm are:\n",
    "\n",
    "n_epochs: 20\n",
    "lr_all: 0.005\n",
    "reg_all: 0.4\n",
    "And the lowest RMSE achieved with these parameters is approximately 0.7392."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58c92c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7385  0.7367  0.7378  0.7374  0.7370  0.7375  0.0006  \n",
      "Fit time          15.61   15.55   15.32   15.01   15.53   15.40   0.22    \n",
      "Test time         44.79   32.95   17.14   14.35   9.50    23.75   13.13   \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the dataset (assuming the 'data' variable holds your Dataset object)\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "# Assuming 'books_with_ratings' holds your data\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'Book-Title', 'Numeric-Rating-Category']], reader)\n",
    "\n",
    "# Initialize the SVD algorithm with the optimized parameters\n",
    "algo = SVD(n_epochs=20, lr_all=0.005, reg_all=0.4)\n",
    "\n",
    "# Perform cross-validation and print results\n",
    "cross_val_results = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5aeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0297905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9006ef9e",
   "metadata": {},
   "source": [
    "### Added Unknown to ratings to check the outut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ecd2622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rebecca', 'The Key to Rebecca', 'Rebecca (Compact Books)', \"Rebecca (The world's best reading)\", 'My Cousin Rachel (Common Reader Editions)', 'Q', 'Cry No More', 'Under Fire', 'Now You See It . . .', 'Once']\n"
     ]
    }
   ],
   "source": [
    "def categorize_rating(rating):\n",
    "    if rating <= 4:\n",
    "        return 'Low'\n",
    "    elif rating <= 7:\n",
    "        return 'Medium'\n",
    "    elif rating == 0:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Split and clean the 'Location' column in users_df\n",
    "users[['City', 'State', 'Country']] = users['Location'].str.split(',', n=2, expand=True)\n",
    "users['City'] = users['City'].str.strip()\n",
    "users['State'] = users['State'].str.strip()\n",
    "users['Country'] = users['Country'].str.strip()\n",
    "\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Rating-Category'] = books_with_ratings['Book-Rating'].apply(categorize_rating)\n",
    "rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3, 'Unknown': 0}\n",
    "books_with_ratings['Numeric-Rating-Category'] = books_with_ratings['Rating-Category'].map(rating_to_numeric)\n",
    "\n",
    "median_age = books_with_ratings['Age'].median()\n",
    "books_with_ratings['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('location', OneHotEncoder(handle_unknown='ignore'), ['Location']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'Book-Title', 'Numeric-Rating-Category']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Rebecca\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7922c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7385  0.7353  0.7375  0.7375  0.7373  0.7372  0.0011  \n",
      "Fit time          23.34   21.43   25.47   22.64   29.17   24.41   2.72    \n",
      "Test time         4.83    3.34    3.79    5.30    3.12    4.08    0.85    \n",
      "{'test_rmse': array([0.73850347, 0.73528242, 0.7374635 , 0.73753792, 0.73734216]), 'fit_time': (23.33500051498413, 21.43100380897522, 25.471997499465942, 22.635960340499878, 29.169997453689575), 'test_time': (4.833484411239624, 3.33799409866333, 3.7860007286071777, 5.298000812530518, 3.1210033893585205)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41550206306433424"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n",
    "average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2fca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "650a7321",
   "metadata": {},
   "source": [
    "### Adding Location as City and try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fe84bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rebecca', 'The Key to Rebecca', 'Rebecca (Compact Books)', \"Rebecca (The world's best reading)\", 'My Cousin Rachel (Common Reader Editions)', 'Q', 'Cry No More', 'Under Fire', 'Now You See It . . .', 'Twelve']\n"
     ]
    }
   ],
   "source": [
    "def categorize_rating(rating):\n",
    "    if rating <= 4:\n",
    "        return 'Low'\n",
    "    elif rating <= 7:\n",
    "        return 'Medium'\n",
    "    elif rating == 0:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Split and clean the 'Location' column in users_df\n",
    "users[['City', 'State', 'Country']] = users['Location'].str.split(',', n=2, expand=True)\n",
    "users['City'] = users['City'].str.strip()\n",
    "users['State'] = users['State'].str.strip()\n",
    "users['Country'] = users['Country'].str.strip()\n",
    "\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Rating-Category'] = books_with_ratings['Book-Rating'].apply(categorize_rating)\n",
    "rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3, 'Unknown': 0}\n",
    "books_with_ratings['Numeric-Rating-Category'] = books_with_ratings['Rating-Category'].map(rating_to_numeric)\n",
    "\n",
    "median_age = books_with_ratings['Age'].median()\n",
    "books_with_ratings['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('city', OneHotEncoder(handle_unknown='ignore'), ['City']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'Book-Title', 'Numeric-Rating-Category']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Rebecca\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6efe29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7365  0.7357  0.7382  0.7379  0.7358  0.7368  0.0011  \n",
      "Fit time          25.58   26.12   28.27   28.07   27.18   27.04   1.06    \n",
      "Test time         6.44    3.32    7.65    10.13   3.49    6.20    2.58    \n",
      "{'test_rmse': array([0.736534  , 0.73565711, 0.73819757, 0.7379298 , 0.73579525]), 'fit_time': (25.58199906349182, 26.116001844406128, 28.269001960754395, 28.072001457214355, 27.17755365371704), 'test_time': (6.436000347137451, 3.3169987201690674, 7.64788031578064, 10.12947678565979, 3.4851627349853516)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41550206306433424"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n",
    "average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1c466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e2ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "214771f0",
   "metadata": {},
   "source": [
    "### Removing zero ratings rows and trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b81d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove rows in the ratings DataFrame where a specific ISBN has only zero ratings and no non-zero ratings, you can follow these steps:\n",
    "#To remove records from the ratings DataFrame where there is only a single user associated with a single ISBN and that rating is zero, you'll need to:\n",
    "\n",
    "def handle_ratings(ratings):\n",
    "    print(ratings)\n",
    "\n",
    "    # Group by 'ISBN' and check if any of the ratings are non-zero\n",
    "    isbn_with_non_zero_ratings = ratings.groupby('ISBN')['Book-Rating'].any()\n",
    "    print(isbn_with_non_zero_ratings)\n",
    "    # Filter out ISBNs that have only zero ratings\n",
    "    ratings = ratings[ratings['ISBN'].isin(isbn_with_non_zero_ratings[isbn_with_non_zero_ratings].index)]\n",
    "    print(ratings)\n",
    "    \n",
    "        # Step 1: Identify users with only one rating\n",
    "    user_rating_counts = ratings['User-ID'].value_counts()\n",
    "    single_rating_users = user_rating_counts[user_rating_counts == 1].index\n",
    "\n",
    "    # Step 2: Filter ratings to include only single rating users\n",
    "    single_ratings = ratings[ratings['User-ID'].isin(single_rating_users)]\n",
    "\n",
    "    # Step 3: Identify single ratings that are zero\n",
    "    zero_rating_single_users = single_ratings[single_ratings['Book-Rating'] == 0]['User-ID']\n",
    "\n",
    "    # Step 4: Remove these records from the original DataFrame\n",
    "    ratings = ratings[~((ratings['User-ID'].isin(zero_rating_single_users)) & (ratings['Book-Rating'] == 0))]\n",
    "    \n",
    "    print(ratings)\n",
    "    \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "089e30a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         User-ID         ISBN  Book-Rating\n",
      "0         276725   034545104X            0\n",
      "1         276726   0155061224            5\n",
      "2         276727   0446520802            0\n",
      "3         276729   052165615X            3\n",
      "4         276729   0521795028            6\n",
      "...          ...          ...          ...\n",
      "1149775   276704   1563526298            9\n",
      "1149776   276706   0679447156            0\n",
      "1149777   276709   0515107662           10\n",
      "1149778   276721   0590442449           10\n",
      "1149779   276723  05162443314            8\n",
      "\n",
      "[1149780 rows x 3 columns]\n",
      "ISBN\n",
      " 0330299891      True\n",
      " 0375404120      True\n",
      " 0586045007     False\n",
      " 9022906116      True\n",
      " 9032803328     False\n",
      "                ...  \n",
      "cn113107        False\n",
      "ooo7156103       True\n",
      "Â§423350229     False\n",
      "Â´3499128624     True\n",
      "ÃÂ½crosoft      True\n",
      "Name: Book-Rating, Length: 340556, dtype: bool\n",
      "         User-ID         ISBN  Book-Rating\n",
      "0         276725   034545104X            0\n",
      "1         276726   0155061224            5\n",
      "2         276727   0446520802            0\n",
      "3         276729   052165615X            3\n",
      "4         276729   0521795028            6\n",
      "...          ...          ...          ...\n",
      "1149775   276704   1563526298            9\n",
      "1149776   276706   0679447156            0\n",
      "1149777   276709   0515107662           10\n",
      "1149778   276721   0590442449           10\n",
      "1149779   276723  05162443314            8\n",
      "\n",
      "[927751 rows x 3 columns]\n",
      "         User-ID         ISBN  Book-Rating\n",
      "1         276726   0155061224            5\n",
      "3         276729   052165615X            3\n",
      "4         276729   0521795028            6\n",
      "6         276736   3257224281            8\n",
      "7         276737   0600570967            6\n",
      "...          ...          ...          ...\n",
      "1149773   276704   0806917695            5\n",
      "1149775   276704   1563526298            9\n",
      "1149777   276709   0515107662           10\n",
      "1149778   276721   0590442449           10\n",
      "1149779   276723  05162443314            8\n",
      "\n",
      "[909730 rows x 3 columns]\n",
      "['Rebecca', 'The Key to Rebecca', 'Rebecca (Compact Books)', 'My Cousin Rachel (Common Reader Editions)', 'Q', 'Cry No More', 'Under Fire', 'Now You See It . . .', 'Twelve', 'Once']\n"
     ]
    }
   ],
   "source": [
    "def categorize_rating(rating):\n",
    "    if rating <= 4:\n",
    "        return 'Low'\n",
    "    elif rating <= 7:\n",
    "        return 'Medium'\n",
    "    #elif rating == 0:\n",
    "    #    return 'Unknown'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('Books.csv', encoding='latin-1')\n",
    "ratings = pd.read_csv('Ratings.csv', encoding='latin-1')\n",
    "users = pd.read_csv('Users.csv', encoding='latin-1')\n",
    "\n",
    "users['Location'] = users['Location'].str.lower() ## converitng location into lower coses. \n",
    "users.loc[:, 'Location'] = users['Location'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Split and clean the 'Location' column in users_df\n",
    "users[['City', 'State', 'Country']] = users['Location'].str.split(',', n=2, expand=True)\n",
    "users['City'] = users['City'].str.strip()\n",
    "users['State'] = users['State'].str.strip()\n",
    "users['Country'] = users['Country'].str.strip()\n",
    "\n",
    "\n",
    "#handling ratings \n",
    "ratings = handle_ratings(ratings)\n",
    "\n",
    "\n",
    "\n",
    "# Merge datasets\n",
    "books_with_ratings = pd.merge(books, ratings, on='ISBN')\n",
    "books_with_ratings = pd.merge(books_with_ratings, users, on='User-ID')\n",
    "\n",
    "books_with_ratings['Rating-Category'] = books_with_ratings['Book-Rating'].apply(categorize_rating)\n",
    "#rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3, 'Unknown': 0}\n",
    "rating_to_numeric = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "books_with_ratings['Numeric-Rating-Category'] = books_with_ratings['Rating-Category'].map(rating_to_numeric)\n",
    "\n",
    "median_age = books_with_ratings['Age'].median()\n",
    "books_with_ratings['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'] = pd.to_numeric(books_with_ratings['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "books_with_ratings['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "books_with_ratings['Location'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, handling non-numeric entries\n",
    "\n",
    "books_with_ratings['Year-Of-Publication'].fillna(books_with_ratings['Year-Of-Publication'].median(), inplace=True)\n",
    "\n",
    "# Preprocessing pipeline for additional features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('author', OneHotEncoder(handle_unknown='ignore'), ['Book-Author']),\n",
    "        ('city', OneHotEncoder(handle_unknown='ignore'), ['City']),\n",
    "        ('year', StandardScaler(), ['Year-Of-Publication'])\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "additional_features = preprocessor.fit_transform(books_with_ratings)\n",
    "\n",
    "# Content-Based Recommender for Book Titles\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(books_with_ratings['Book-Title'])\n",
    "\n",
    "# Combine title features with additional features\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_features = hstack([count_matrix, additional_features])\n",
    "\n",
    "combined_features_csr = csr_matrix(combined_features)\n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(books_with_ratings[['User-ID', 'Book-Title', 'Numeric-Rating-Category']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Update indices after combining features\n",
    "indices = pd.Series(range(len(books_with_ratings)), index=books_with_ratings['Book-Title']).drop_duplicates()\n",
    "\n",
    "# Hybrid Recommendation Function\n",
    "def get_recommendations(user_id, book_title):\n",
    "    if book_title not in indices:\n",
    "        return f\"Book title '{book_title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[book_title]\n",
    "\n",
    "    # Calculate cosine similarity for the selected book\n",
    "    cosine_sim = cosine_similarity(combined_features_csr[idx], combined_features_csr)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "\n",
    "    # Predict ratings and filter unique books\n",
    "    books_predictions = {}\n",
    "    for i, _ in sim_scores:\n",
    "        title = books_with_ratings.iloc[i]['Book-Title']\n",
    "        if title not in books_predictions:\n",
    "            books_predictions[title] = svd.predict(user_id, books_with_ratings.iloc[i]['ISBN']).est\n",
    "\n",
    "    # Sort books by predicted rating and select top 10\n",
    "    top_books = sorted(books_predictions, key=books_predictions.get, reverse=True)[:10]\n",
    "\n",
    "    return top_books\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(276726, \"Rebecca\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df79adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7745  0.7750  0.7731  0.7757  0.7744  0.7745  0.0008  \n",
      "Fit time          14.08   14.05   14.16   17.49   13.87   14.73   1.39    \n",
      "Test time         3.20    3.21    1.84    2.74    2.48    2.70    0.51    \n",
      "{'test_rmse': array([0.77451942, 0.7750083 , 0.77309069, 0.77565715, 0.77438842]), 'fit_time': (14.076028823852539, 14.049004077911377, 14.157811880111694, 17.491998195648193, 13.865998983383179), 'test_time': (3.2026917934417725, 3.2109971046447754, 1.8419890403747559, 2.73699951171875, 2.4829983711242676)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31050545169770155"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "svd = SVD()\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cross_val_results = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(cross_val_results)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_vector(book_title, feature_matrix, book_indices):\n",
    "    # Retrieve the row from the feature matrix corresponding to the given book title\n",
    "    idx = book_indices[book_title]\n",
    "    return feature_matrix[idx]\n",
    "\n",
    "def calculate_average_similarity(input_book_vector, recommended_books, feature_matrix, book_indices):\n",
    "    similarities = []\n",
    "    for book in recommended_books:\n",
    "        book_vector = get_feature_vector(book, feature_matrix, book_indices)\n",
    "        if book_vector is not None:\n",
    "            similarity = cosine_similarity(input_book_vector, book_vector)\n",
    "            similarities.append(similarity[0][0])\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "# Example usage\n",
    "input_book_vector = get_feature_vector(\"Classical Mythology\", combined_features_csr, indices)\n",
    "recommended_books = get_recommendations(276726, \"Classical Mythology\")\n",
    "average_similarity = calculate_average_similarity(input_book_vector, recommended_books, combined_features_csr, indices)\n",
    "average_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e5c5d",
   "metadata": {},
   "source": [
    " With 0 rating as Unknown , We got similarity as .31, without  rating as unknow , we got similarity as same . SO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a42c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05147ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e2c23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7752384163617441\n",
      "{'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "## HYer Arameter Tuning \n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_epochs': [5, 10, 20],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.4, 0.6]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# Use the best parameters for SVD\n",
    "algo = SVD(n_epochs=gs.best_params['rmse']['n_epochs'], lr_all=gs.best_params['rmse']['lr_all'], reg_all=gs.best_params['rmse']['reg_all'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e20d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb9424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66345f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
